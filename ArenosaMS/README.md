# ArenosaMS
Our initial dataset and prototype for code. Parents M and S. Crosses MxS and SxM. Four biological replicates. Processed with Slurm on Saga.

## Directory Layout
* BR1 (and similar for BR2, BR3, BR4: 4 total)
  * MxM (and similar for SxS, MxS, SxM)
    * MxM_BR1_R1_trim.fq.gz (soft link)
    * MxM_BR1_R2_trim.fq.gz (soft link)
    * meryl_all.db
    * meryl_distinct.db
  * SminusM (and similar for MminusS: 2 total)
    * meryl_first.db -> ../SxS/meryl_distinct.db (soft link)
    * meryl_second.db -> ../MxM/meryl_distinct.db (soft link(
    * meryl_diff.db
  * IntersectSxM_SminusM (and similar for MxS and MminusS: 4 total)
    * meryl_first.db -> ../SxM/meryl_distinct.db (soft link)
    * meryl_second.db -> ../SminusM/meryl_diff.db (soft link)
    * meryl_intersect.db  

## Scripts

### Compute the k-mer clouds
* run_meryl.sh - Count k-mers in one parent.
* run_diff.sh - Retain k-mers specific to one parent.
* run_intersect.sh - Retain k-mers from a cross also specific to one parent.

### Classify reads
* grid_mer_filter.sh - Submit a job to the grid for one biological replicate.
* individual_mer_filter.sh - Launch the Python with 5 parameters.
* mer_filter_reads.py - Stream a pair of fastq files, write a pair of IDs lists, one maternal, one paternal.

### Utilities
* sample_reads.sh - Sample down a pair of fastq files to first 10M read pairs.
* extract_gene_per_read.sh - Given a bam file, make csv file of "readID,geneID". Assume sorted by readID so second ID can be ignored. Assume bam already filtered to retain end-to-end concordant-pair maps only.
* run_statistics.sh - Count reads assigned to mat and pat. Write to stdout.
* grid_validate.sh - Modified grid_mer_filter.sh used for test runs on partial fastq files generated by sample_reads. Validated KCloud by classifying parental reads as if they were cross reads. Output directories M_SxM, S_SxM, M_MxS, S_MxS where M_SxM means classify MxM reads using the SxM k-mer cloud.

